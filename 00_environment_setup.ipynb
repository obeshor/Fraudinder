{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fsv4jGuU89rX"
   },
   "source": [
    "# FraudDetection - Environment Setup\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://console.cloud.google.com/ai-platform/notebooks/deploy-notebook?download_url=https://github.com/obeshor/FraudDetection/raw/main/00_environment_setup.ipynb\">\n",
    "       <img src=\"https://www.gstatic.com/cloud/images/navigation/vertex-ai.svg\" alt=\"Google Cloud Notebooks\">Open in Cloud Notebook\n",
    "    </a>\n",
    "  </td> \n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github.com/obeshor/FraudDetection/blob/main/00_environment_setup.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> Open in Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://github.com/github.com/obeshor/FraudDetection/blob/main/00_environment_setup.ipynb\">\n",
    "        <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      View on GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "827c41ab1a12"
   },
   "source": [
    "## Overview\n",
    "\n",
    "[FraudFinder](https://github.com/googlecloudplatform/fraudfinder) is a series of labs on how to build a real-time fraud detection system on Google Cloud. Throughout the FraudFinder labs, you will learn how to read historical bank transaction data stored in data warehouse, read from a live stream of new transactions, perform exploratory data analysis (EDA), do feature engineering, ingest features into a feature store, train a model using feature store, register your model in a model registry, evaluate your model, deploy your model to an endpoint, do real-time inference on your model with feature store, and monitor your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "45f6e923dc75"
   },
   "source": [
    "### Objective\n",
    "\n",
    "Before you run this notebook, make sure that you have completed the steps in [README](README.md).\n",
    "\n",
    "In this notebook, you will setup your environment for Fraudfinder to be used in subsequent labs.\n",
    "\n",
    "This lab uses the following Google Cloud services and resources:\n",
    "\n",
    "- [Vertex AI](https://cloud.google.com/vertex-ai/)\n",
    "- [BigQuery](https://cloud.google.com/bigquery/)\n",
    "- [Google Cloud Storage](https://cloud.google.com/storage)\n",
    "- [Pub/Sub](https://cloud.google.com/pubsub/)\n",
    "\n",
    "Steps performed in this notebook:\n",
    "\n",
    "- Setup your environment.\n",
    "- Load historical bank transactions into BigQuery.\n",
    "- Read data from BigQuery tables.\n",
    "- Read data from Pub/Sub topics, which contain a live stream of new transactions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8b5e2e2a7bdb"
   },
   "source": [
    "### Costs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "04c1dae4ca17"
   },
   "source": [
    "This tutorial uses billable components of Google Cloud:\n",
    "\n",
    "* Vertex AI\n",
    "* Cloud Storage\n",
    "* Pub/Sub\n",
    "* BigQuery\n",
    "\n",
    "Learn about [Vertex AI\n",
    "pricing](https://cloud.google.com/vertex-ai/pricing), [Cloud Storage\n",
    "pricing](https://cloud.google.com/storage/pricing), [Pub/Sub pricing](https://cloud.google.com/pubsub/pricing), [BigQuery pricing](https://cloud.google.com/bigquery/pricing) and use the [Pricing\n",
    "Calculator](https://cloud.google.com/products/calculator/)\n",
    "to generate a cost estimate based on your projected usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "773901ca47fd"
   },
   "source": [
    "### Install additional packages\n",
    "\n",
    "Install the following packages required to execute this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "b7c7ce6bbf03",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-cloud-pubsub<=2.18.4 (from -r requirements.txt (line 1))\n",
      "  Downloading google_cloud_pubsub-2.18.4-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting google-cloud-bigquery<=3.13.0 (from -r requirements.txt (line 2))\n",
      "  Downloading google_cloud_bigquery-3.13.0-py2.py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting google-cloud-bigquery-storage<=2.22.0 (from -r requirements.txt (line 3))\n",
      "  Downloading google_cloud_bigquery_storage-2.22.0-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting google-cloud-aiplatform<=1.36.1 (from -r requirements.txt (line 5))\n",
      "  Downloading google_cloud_aiplatform-1.36.1-py2.py3-none-any.whl.metadata (27 kB)\n",
      "Collecting google-cloud-pipeline-components<=0.3.0 (from -r requirements.txt (line 6))\n",
      "  Downloading google_cloud_pipeline_components-0.3.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting plotly<=5.18.0 (from -r requirements.txt (line 7))\n",
      "  Downloading plotly-5.18.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting xgboost<=2.0.1 (from -r requirements.txt (line 8))\n",
      "  Downloading xgboost-2.0.1-py3-none-manylinux2014_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting kfp<=2.3.0 (from -r requirements.txt (line 9))\n",
      "  Downloading kfp-2.3.0.tar.gz (377 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m377.2/377.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting apache_beam==2.53.0 (from apache_beam[gcp]==2.53.0->-r requirements.txt (line 10))\n",
      "  Downloading apache_beam-2.53.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting crcmod<2.0,>=1.7 (from apache_beam==2.53.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10))\n",
      "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting orjson<4,>=3.9.7 (from apache_beam==2.53.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10))\n",
      "  Downloading orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (49 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting dill<0.3.2,>=0.3.1.1 (from apache_beam==2.53.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10))\n",
      "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.0/152.0 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting cloudpickle~=2.2.1 (from apache_beam==2.53.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10))\n",
      "  Downloading cloudpickle-2.2.1-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting fastavro<2,>=0.23.6 (from apache_beam==2.53.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10))\n",
      "  Downloading fastavro-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting fasteners<1.0,>=0.3 (from apache_beam==2.53.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10))\n",
      "  Downloading fasteners-0.19-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: grpcio!=1.48.0,<2,>=1.33.1 in /opt/conda/lib/python3.10/site-packages (from apache_beam==2.53.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (1.62.1)\n",
      "Collecting hdfs<3.0.0,>=2.1.0 (from apache_beam==2.53.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10))\n",
      "  Downloading hdfs-2.7.3.tar.gz (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: httplib2<0.23.0,>=0.8 in /opt/conda/lib/python3.10/site-packages (from apache_beam==2.53.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (0.22.0)\n",
      "Collecting js2py<1,>=0.74 (from apache_beam==2.53.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10))\n",
      "  Downloading Js2Py-0.74-py3-none-any.whl.metadata (868 bytes)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from apache_beam==2.53.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (4.21.1)\n",
      "Collecting jsonpickle<4.0.0,>=3.0.0 (from apache_beam==2.53.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10))\n",
      "  Downloading jsonpickle-3.0.3-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting numpy<1.25.0,>=1.14.3 (from apache_beam==2.53.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10))\n",
      "  Downloading numpy-1.24.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "Collecting objsize<0.7.0,>=0.6.1 (from apache_beam==2.53.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10))\n",
      "  Downloading objsize-0.6.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: packaging>=22.0 in /opt/conda/lib/python3.10/site-packages (from apache_beam==2.53.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (24.0)\n",
      "Collecting pymongo<5.0.0,>=3.8.0 (from apache_beam==2.53.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10))\n",
      "  Downloading pymongo-4.6.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
      "Requirement already satisfied: proto-plus<2,>=1.7.1 in /opt/conda/lib/python3.10/site-packages (from apache_beam==2.53.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (1.23.0)\n",
      "Requirement already satisfied: protobuf!=4.0.*,!=4.21.*,!=4.22.0,!=4.23.*,!=4.24.*,<4.26.0,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from apache_beam==2.53.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (3.20.3)\n",
      "Collecting pydot<2,>=1.2.0 (from apache_beam==2.53.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10))\n",
      "  Downloading pydot-1.4.2-py2.py3-none-any.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /opt/conda/lib/python3.10/site-packages (from apache_beam==2.53.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2018.3 in /opt/conda/lib/python3.10/site-packages (from apache_beam==2.53.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (2024.1)\n",
      "Collecting regex>=2020.6.8 (from apache_beam==2.53.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10))\n",
      "  Downloading regex-2023.12.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.24.0 in /opt/conda/lib/python3.10/site-packages (from apache_beam==2.53.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.0 in /opt/conda/lib/python3.10/site-packages (from apache_beam==2.53.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (4.10.0)\n",
      "Requirement already satisfied: zstandard<1,>=0.18.0 in /opt/conda/lib/python3.10/site-packages (from apache_beam==2.53.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (0.22.0)\n",
      "Collecting pyarrow<15.0.0,>=3.0.0 (from apache_beam==2.53.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10))\n",
      "  Downloading pyarrow-14.0.2-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting pyarrow-hotfix<1 (from apache_beam==2.53.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10))\n",
      "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: cachetools<6,>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (5.3.3)\n",
      "Collecting google-api-core<3,>=2.0.0 (from apache_beam[gcp]==2.53.0->-r requirements.txt (line 10))\n",
      "  Downloading google_api_core-2.17.1-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting google-apitools<0.5.32,>=0.5.31 (from apache_beam[gcp]==2.53.0->-r requirements.txt (line 10))\n",
      "  Downloading google-apitools-0.5.31.tar.gz (173 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.5/173.5 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: google-auth<3,>=1.18.0 in /opt/conda/lib/python3.10/site-packages (from apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (2.28.2)\n",
      "Collecting google-auth-httplib2<0.2.0,>=0.1.0 (from apache_beam[gcp]==2.53.0->-r requirements.txt (line 10))\n",
      "  Downloading google_auth_httplib2-0.1.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting google-cloud-datastore<3,>=2.0.0 (from apache_beam[gcp]==2.53.0->-r requirements.txt (line 10))\n",
      "  Downloading google_cloud_datastore-2.19.0-py2.py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting google-cloud-pubsublite<2,>=1.2.0 (from apache_beam[gcp]==2.53.0->-r requirements.txt (line 10))\n",
      "  Downloading google_cloud_pubsublite-1.9.0-py2.py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: google-cloud-storage<3,>=2.10.0 in /opt/conda/lib/python3.10/site-packages (from apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (2.14.0)\n",
      "Requirement already satisfied: google-cloud-core<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (2.4.1)\n",
      "Collecting google-cloud-bigtable<3,>=2.19.0 (from apache_beam[gcp]==2.53.0->-r requirements.txt (line 10))\n",
      "  Downloading google_cloud_bigtable-2.23.0-py2.py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting google-cloud-spanner<4,>=3.0.0 (from apache_beam[gcp]==2.53.0->-r requirements.txt (line 10))\n",
      "  Downloading google_cloud_spanner-3.44.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting google-cloud-dlp<4,>=3.0.0 (from apache_beam[gcp]==2.53.0->-r requirements.txt (line 10))\n",
      "  Downloading google_cloud_dlp-3.16.0-py2.py3-none-any.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: google-cloud-language<3,>=2.0 in /opt/conda/lib/python3.10/site-packages (from apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (2.13.3)\n",
      "Collecting google-cloud-videointelligence<3,>=2.0 (from apache_beam[gcp]==2.53.0->-r requirements.txt (line 10))\n",
      "  Downloading google_cloud_videointelligence-2.13.3-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting google-cloud-vision<4,>=2 (from apache_beam[gcp]==2.53.0->-r requirements.txt (line 10))\n",
      "  Downloading google_cloud_vision-3.7.2-py2.py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting google-cloud-recommendations-ai<0.11.0,>=0.1.0 (from apache_beam[gcp]==2.53.0->-r requirements.txt (line 10))\n",
      "  Downloading google_cloud_recommendations_ai-0.10.10-py2.py3-none-any.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /opt/conda/lib/python3.10/site-packages (from google-cloud-pubsub<=2.18.4->-r requirements.txt (line 1)) (0.13.0)\n",
      "Requirement already satisfied: grpcio-status>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-pubsub<=2.18.4->-r requirements.txt (line 1)) (1.48.2)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery<=3.13.0->-r requirements.txt (line 2)) (2.7.0)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform<=1.36.1->-r requirements.txt (line 5)) (1.12.3)\n",
      "Requirement already satisfied: shapely<3.0.0dev in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform<=1.36.1->-r requirements.txt (line 5)) (2.0.3)\n",
      "INFO: pip is looking at multiple versions of google-cloud-pipeline-components to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting google-cloud-pipeline-components<=0.3.0 (from -r requirements.txt (line 6))\n",
      "  Downloading google_cloud_pipeline_components-0.2.6-py3-none-any.whl.metadata (5.6 kB)\n",
      "  Downloading google_cloud_pipeline_components-0.2.5-py3-none-any.whl.metadata (5.6 kB)\n",
      "  Downloading google_cloud_pipeline_components-0.2.4-py3-none-any.whl.metadata (5.6 kB)\n",
      "  Downloading google_cloud_pipeline_components-0.2.3-py3-none-any.whl.metadata (5.6 kB)\n",
      "  Downloading google_cloud_pipeline_components-0.2.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "  Downloading google_cloud_pipeline_components-0.2.1-1-py3-none-any.whl.metadata (5.6 kB)\n",
      "  Downloading google_cloud_pipeline_components-0.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "INFO: pip is still looking at multiple versions of google-cloud-pipeline-components to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading google_cloud_pipeline_components-0.1.9-py3-none-any.whl.metadata (5.6 kB)\n",
      "  Downloading google_cloud_pipeline_components-0.1.8-py3-none-any.whl.metadata (5.7 kB)\n",
      "  Downloading google_cloud_pipeline_components-0.1.7-py3-none-any.whl.metadata (5.6 kB)\n",
      "  Downloading google_cloud_pipeline_components-0.1.6-py3-none-any.whl.metadata (5.6 kB)\n",
      "  Downloading google_cloud_pipeline_components-0.1.5-py3-none-any.whl.metadata (1.9 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading google_cloud_pipeline_components-0.1.4-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting kfp<=2.3.0 (from -r requirements.txt (line 9))\n",
      "  Downloading kfp-1.8.22.tar.gz (304 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.9/304.9 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from plotly<=5.18.0->-r requirements.txt (line 7)) (8.2.3)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from xgboost<=2.0.1->-r requirements.txt (line 8)) (1.11.4)\n",
      "Collecting absl-py<2,>=0.9 (from kfp<=2.3.0->-r requirements.txt (line 9))\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: PyYAML<7,>=5.3 in /opt/conda/lib/python3.10/site-packages (from kfp<=2.3.0->-r requirements.txt (line 9)) (6.0.1)\n",
      "Collecting kubernetes<26,>=8.0.0 (from kfp<=2.3.0->-r requirements.txt (line 9))\n",
      "  Downloading kubernetes-25.3.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: google-api-python-client<2,>=1.7.8 in /opt/conda/lib/python3.10/site-packages (from kfp<=2.3.0->-r requirements.txt (line 9)) (1.8.0)\n",
      "Requirement already satisfied: requests-toolbelt<1,>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from kfp<=2.3.0->-r requirements.txt (line 9)) (0.10.1)\n",
      "Collecting kfp-server-api<2.0.0,>=1.1.2 (from kfp<=2.3.0->-r requirements.txt (line 9))\n",
      "  Downloading kfp-server-api-1.8.5.tar.gz (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: tabulate<1,>=0.8.6 in /opt/conda/lib/python3.10/site-packages (from kfp<=2.3.0->-r requirements.txt (line 9)) (0.9.0)\n",
      "Requirement already satisfied: click<9,>=7.1.2 in /opt/conda/lib/python3.10/site-packages (from kfp<=2.3.0->-r requirements.txt (line 9)) (8.1.7)\n",
      "Requirement already satisfied: Deprecated<2,>=1.2.7 in /opt/conda/lib/python3.10/site-packages (from kfp<=2.3.0->-r requirements.txt (line 9)) (1.2.14)\n",
      "Collecting strip-hints<1,>=0.1.8 (from kfp<=2.3.0->-r requirements.txt (line 9))\n",
      "  Downloading strip-hints-0.1.10.tar.gz (29 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: docstring-parser<1,>=0.7.3 in /opt/conda/lib/python3.10/site-packages (from kfp<=2.3.0->-r requirements.txt (line 9)) (0.15)\n",
      "Collecting kfp-pipeline-spec<0.2.0,>=0.1.16 (from kfp<=2.3.0->-r requirements.txt (line 9))\n",
      "  Downloading kfp_pipeline_spec-0.1.16-py3-none-any.whl.metadata (323 bytes)\n",
      "Collecting fire<1,>=0.3.1 (from kfp<=2.3.0->-r requirements.txt (line 9))\n",
      "  Downloading fire-0.6.0.tar.gz (88 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.4/88.4 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: uritemplate<4,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from kfp<=2.3.0->-r requirements.txt (line 9)) (3.0.1)\n",
      "Requirement already satisfied: urllib3<2 in /opt/conda/lib/python3.10/site-packages (from kfp<=2.3.0->-r requirements.txt (line 9)) (1.26.18)\n",
      "Collecting pydantic<2,>=1.8.2 (from kfp<=2.3.0->-r requirements.txt (line 9))\n",
      "  Downloading pydantic-1.10.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (150 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.2/150.2 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typer<1.0,>=0.3.2 in /opt/conda/lib/python3.10/site-packages (from kfp<=2.3.0->-r requirements.txt (line 9)) (0.9.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.10/site-packages (from Deprecated<2,>=1.2.7->kfp<=2.3.0->-r requirements.txt (line 9)) (1.16.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from fire<1,>=0.3.1->kfp<=2.3.0->-r requirements.txt (line 9)) (1.16.0)\n",
      "Collecting termcolor (from fire<1,>=0.3.1->kfp<=2.3.0->-r requirements.txt (line 9))\n",
      "  Downloading termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core<3,>=2.0.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (1.63.0)\n",
      "INFO: pip is looking at multiple versions of google-api-python-client to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting google-api-python-client<2,>=1.7.8 (from kfp<=2.3.0->-r requirements.txt (line 9))\n",
      "  Downloading google_api_python_client-1.12.11-py2.py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: oauth2client>=1.4.12 in /opt/conda/lib/python3.10/site-packages (from google-apitools<0.5.32,>=0.5.31->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (4.1.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.18.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.18.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (4.9)\n",
      "Requirement already satisfied: overrides<8.0.0,>=6.0.1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-pubsublite<2,>=1.2.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (7.7.0)\n",
      "Requirement already satisfied: sqlparse>=0.4.4 in /opt/conda/lib/python3.10/site-packages (from google-cloud-spanner<4,>=3.0.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (0.4.4)\n",
      "Collecting grpc-interceptor>=0.15.4 (from google-cloud-spanner<4,>=3.0.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10))\n",
      "  Downloading grpc_interceptor-0.15.4-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage<3,>=2.10.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (1.5.0)\n",
      "Collecting docopt (from hdfs<3.0.0,>=2.1.0->apache_beam==2.53.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10))\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /opt/conda/lib/python3.10/site-packages (from httplib2<0.23.0,>=0.8->apache_beam==2.53.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (3.1.2)\n",
      "Collecting tzlocal>=1.2 (from js2py<1,>=0.74->apache_beam==2.53.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10))\n",
      "  Downloading tzlocal-5.2-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting pyjsparser>=2.5.1 (from js2py<1,>=0.74->apache_beam==2.53.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10))\n",
      "  Downloading pyjsparser-2.7.1.tar.gz (24 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.0.0->apache_beam==2.53.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.0.0->apache_beam==2.53.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.0.0->apache_beam==2.53.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (0.33.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.0.0->apache_beam==2.53.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (0.18.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp<=2.3.0->-r requirements.txt (line 9)) (2024.2.2)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in /opt/conda/lib/python3.10/site-packages (from kubernetes<26,>=8.0.0->kfp<=2.3.0->-r requirements.txt (line 9)) (69.1.1)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /opt/conda/lib/python3.10/site-packages (from kubernetes<26,>=8.0.0->kfp<=2.3.0->-r requirements.txt (line 9)) (1.7.0)\n",
      "Requirement already satisfied: requests-oauthlib in /opt/conda/lib/python3.10/site-packages (from kubernetes<26,>=8.0.0->kfp<=2.3.0->-r requirements.txt (line 9)) (1.4.0)\n",
      "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo<5.0.0,>=3.8.0->apache_beam==2.53.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10))\n",
      "  Downloading dnspython-2.6.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.24.0->apache_beam==2.53.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.24.0->apache_beam==2.53.0->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (3.6)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.10/site-packages (from strip-hints<1,>=0.1.8->kfp<=2.3.0->-r requirements.txt (line 9)) (0.42.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /opt/conda/lib/python3.10/site-packages (from oauth2client>=1.4.12->google-apitools<0.5.32,>=0.5.31->apache_beam[gcp]==2.53.0->-r requirements.txt (line 10)) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib->kubernetes<26,>=8.0.0->kfp<=2.3.0->-r requirements.txt (line 9)) (3.2.2)\n",
      "Downloading apache_beam-2.53.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.8/14.8 MB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_cloud_pubsub-2.18.4-py2.py3-none-any.whl (265 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.9/265.9 kB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_cloud_bigquery-3.13.0-py2.py3-none-any.whl (222 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m222.8/222.8 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_cloud_bigquery_storage-2.22.0-py2.py3-none-any.whl (190 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.9/190.9 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_cloud_aiplatform-1.36.1-py2.py3-none-any.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_cloud_pipeline_components-0.1.4-py3-none-any.whl (81 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.7/81.7 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading plotly-5.18.0-py3-none-any.whl (15.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.6/15.6 MB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading xgboost-2.0.1-py3-none-manylinux2014_x86_64.whl (297.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.1/297.1 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.5/126.5 kB\u001b[0m \u001b[31m809.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
      "Downloading fastavro-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading fasteners-0.19-py3-none-any.whl (18 kB)\n",
      "Downloading google_api_core-2.17.1-py3-none-any.whl (137 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.0/137.0 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_api_python_client-1.12.11-py2.py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_auth_httplib2-0.1.1-py2.py3-none-any.whl (9.3 kB)\n",
      "Downloading google_cloud_bigtable-2.23.0-py2.py3-none-any.whl (357 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m357.5/357.5 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_cloud_datastore-2.19.0-py2.py3-none-any.whl (176 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.4/176.4 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_cloud_dlp-3.16.0-py2.py3-none-any.whl (167 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.3/167.3 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_cloud_pubsublite-1.9.0-py2.py3-none-any.whl (287 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.3/287.3 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_cloud_recommendations_ai-0.10.10-py2.py3-none-any.whl (180 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.3/180.3 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_cloud_spanner-3.44.0-py2.py3-none-any.whl (357 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m357.2/357.2 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_cloud_videointelligence-2.13.3-py2.py3-none-any.whl (240 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.4/240.4 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_cloud_vision-3.7.2-py2.py3-none-any.whl (459 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.6/459.6 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading Js2Py-0.74-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading jsonpickle-3.0.3-py3-none-any.whl (40 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kfp_pipeline_spec-0.1.16-py3-none-any.whl (19 kB)\n",
      "Downloading kubernetes-25.3.0-py2.py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.24.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading objsize-0.6.1-py3-none-any.whl (9.3 kB)\n",
      "Downloading orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-14.0.2-cp310-cp310-manylinux_2_28_x86_64.whl (38.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.0/38.0 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Downloading pydantic-1.10.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydot-1.4.2-py2.py3-none-any.whl (21 kB)\n",
      "Downloading pymongo-4.6.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (677 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m677.2/677.2 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2023.12.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m774.0/774.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading grpc_interceptor-0.15.4-py3-none-any.whl (20 kB)\n",
      "Downloading tzlocal-5.2-py3-none-any.whl (17 kB)\n",
      "Downloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Building wheels for collected packages: kfp, crcmod, dill, fire, google-apitools, hdfs, kfp-server-api, strip-hints, pyjsparser, docopt\n",
      "  Building wheel for kfp (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kfp: filename=kfp-1.8.22-py3-none-any.whl size=426966 sha256=2856a9624579a9bc173239666d6129d5db809f5fdcdc6242a79da29170bd368a\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/74/c0/fc/bf0ab209fd6ae814d7efbc821076e948c3e4884f846583ab58\n",
      "  Building wheel for crcmod (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for crcmod: filename=crcmod-1.7-cp310-cp310-linux_x86_64.whl size=23092 sha256=74b529dd5f69a1454c2f6b7060e00fbc44f27356b6b22441710bd3d3a519fc7e\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/85/4c/07/72215c529bd59d67e3dac29711d7aba1b692f543c808ba9e86\n",
      "  Building wheel for dill (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78540 sha256=546a7d57ed128d5d6608439e118ee36afb1576e8927b5a4c38b87d72321e91da\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/ea/e2/86/64980d90e297e7bf2ce588c2b96e818f5399c515c4bb8a7e4f\n",
      "  Building wheel for fire (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fire: filename=fire-0.6.0-py2.py3-none-any.whl size=117031 sha256=57ef995ceb92e57fe84593e88e858176278b3a0cb0aab43f19a4f0738c810a60\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/d6/6d/5d/5b73fa0f46d01a793713f8859201361e9e581ced8c75e5c6a3\n",
      "  Building wheel for google-apitools (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for google-apitools: filename=google_apitools-0.5.31-py3-none-any.whl size=131015 sha256=21c792c0228bf919d2f8233444c5c8681dcf3037156a522dbe9a0e3ca105861d\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/04/b7/e0/9712f8c23a5da3d9d16fb88216b897bf60e85b12f5470f26ee\n",
      "  Building wheel for hdfs (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for hdfs: filename=hdfs-2.7.3-py3-none-any.whl size=34325 sha256=9ae89d34520f6228bb5e55ee8cc8ad5cec2df4aa5d7b8e4a493b8080cf455af8\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/e5/8d/b6/99c1c0a3ac5788c866b0ecd3f48b0134a5910e6ed26011800b\n",
      "  Building wheel for kfp-server-api (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kfp-server-api: filename=kfp_server_api-1.8.5-py3-none-any.whl size=99695 sha256=da001eade2b73d666f8587ef8b7df7d67ed006c1773860ce422b40997945198d\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/c5/97/d5/e8a0f596dc85f5cfe383c800fbf3e29a99853bb54e01f26fca\n",
      "  Building wheel for strip-hints (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for strip-hints: filename=strip_hints-0.1.10-py2.py3-none-any.whl size=22283 sha256=b2eb750c01ec24f91888e540fbef47cb9f0103c46b7543f79251df66af5b1241\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/19/fd/dc/1192a4b454695fa9f0c95b17597a44b200d9fcf0eeb771d104\n",
      "  Building wheel for pyjsparser (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyjsparser: filename=pyjsparser-2.7.1-py3-none-any.whl size=25984 sha256=13ff62916f9644203c70909ebc738f9bfc0e9ac7da3387915d96e81518618f17\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/5e/81/26/5956478df303e2bf5a85a5df595bb307bd25948a4bab69f7c7\n",
      "  Building wheel for docopt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=7c101bc2972b20b03caf9dc6c5653c3247c7bf25e9dc7c1bcf2a65cfbbcd2cb5\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
      "Successfully built kfp crcmod dill fire google-apitools hdfs kfp-server-api strip-hints pyjsparser docopt\n",
      "Installing collected packages: pyjsparser, docopt, crcmod, tzlocal, termcolor, strip-hints, regex, pydot, pydantic, pyarrow-hotfix, plotly, orjson, objsize, numpy, kfp-pipeline-spec, jsonpickle, grpc-interceptor, fasteners, fastavro, dnspython, dill, cloudpickle, absl-py, pymongo, pyarrow, kfp-server-api, js2py, hdfs, fire, xgboost, kubernetes, google-auth-httplib2, google-apitools, google-api-core, google-api-python-client, apache_beam, google-cloud-vision, google-cloud-videointelligence, google-cloud-spanner, google-cloud-recommendations-ai, google-cloud-pubsub, google-cloud-dlp, google-cloud-datastore, google-cloud-bigtable, google-cloud-bigquery-storage, google-cloud-bigquery, kfp, google-cloud-pubsublite, google-cloud-aiplatform, google-cloud-pipeline-components\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 2.6.4\n",
      "    Uninstalling pydantic-2.6.4:\n",
      "      Successfully uninstalled pydantic-2.6.4\n",
      "  Attempting uninstall: plotly\n",
      "    Found existing installation: plotly 5.19.0\n",
      "    Uninstalling plotly-5.19.0:\n",
      "      Successfully uninstalled plotly-5.19.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.25.2\n",
      "    Uninstalling numpy-1.25.2:\n",
      "      Successfully uninstalled numpy-1.25.2\n",
      "  Attempting uninstall: kfp-pipeline-spec\n",
      "    Found existing installation: kfp-pipeline-spec 0.2.2\n",
      "    Uninstalling kfp-pipeline-spec-0.2.2:\n",
      "      Successfully uninstalled kfp-pipeline-spec-0.2.2\n",
      "  Attempting uninstall: cloudpickle\n",
      "    Found existing installation: cloudpickle 3.0.0\n",
      "    Uninstalling cloudpickle-3.0.0:\n",
      "      Successfully uninstalled cloudpickle-3.0.0\n",
      "  Attempting uninstall: absl-py\n",
      "    Found existing installation: absl-py 2.1.0\n",
      "    Uninstalling absl-py-2.1.0:\n",
      "      Successfully uninstalled absl-py-2.1.0\n",
      "\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/opt/conda/lib/python3.10/site-packages/~bsl'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 15.0.1\n",
      "    Uninstalling pyarrow-15.0.1:\n",
      "      Successfully uninstalled pyarrow-15.0.1\n",
      "  Attempting uninstall: kfp-server-api\n",
      "    Found existing installation: kfp-server-api 2.0.5\n",
      "    Uninstalling kfp-server-api-2.0.5:\n",
      "      Successfully uninstalled kfp-server-api-2.0.5\n",
      "  Attempting uninstall: kubernetes\n",
      "    Found existing installation: kubernetes 26.1.0\n",
      "    Uninstalling kubernetes-26.1.0:\n",
      "      Successfully uninstalled kubernetes-26.1.0\n",
      "  Attempting uninstall: google-auth-httplib2\n",
      "    Found existing installation: google-auth-httplib2 0.2.0\n",
      "    Uninstalling google-auth-httplib2-0.2.0:\n",
      "      Successfully uninstalled google-auth-httplib2-0.2.0\n",
      "  Attempting uninstall: google-api-core\n",
      "    Found existing installation: google-api-core 1.34.1\n",
      "    Uninstalling google-api-core-1.34.1:\n",
      "      Successfully uninstalled google-api-core-1.34.1\n",
      "\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/opt/conda/lib/python3.10/site-packages/google/~pi_core'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Attempting uninstall: google-api-python-client\n",
      "    Found existing installation: google-api-python-client 1.8.0\n",
      "    Uninstalling google-api-python-client-1.8.0:\n",
      "      Successfully uninstalled google-api-python-client-1.8.0\n",
      "  Attempting uninstall: google-cloud-datastore\n",
      "    Found existing installation: google-cloud-datastore 1.15.5\n",
      "    Uninstalling google-cloud-datastore-1.15.5:\n",
      "      Successfully uninstalled google-cloud-datastore-1.15.5\n",
      "\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/opt/conda/lib/python3.10/site-packages/google/cloud/~atastore'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/opt/conda/lib/python3.10/site-packages/google/cloud/~atastore_v1'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Attempting uninstall: google-cloud-bigquery-storage\n",
      "    Found existing installation: google-cloud-bigquery-storage 2.24.0\n",
      "    Uninstalling google-cloud-bigquery-storage-2.24.0:\n",
      "      Successfully uninstalled google-cloud-bigquery-storage-2.24.0\n",
      "  Attempting uninstall: google-cloud-bigquery\n",
      "    Found existing installation: google-cloud-bigquery 3.19.0\n",
      "    Uninstalling google-cloud-bigquery-3.19.0:\n",
      "      Successfully uninstalled google-cloud-bigquery-3.19.0\n",
      "  Attempting uninstall: kfp\n",
      "    Found existing installation: kfp 2.5.0\n",
      "    Uninstalling kfp-2.5.0:\n",
      "      Successfully uninstalled kfp-2.5.0\n",
      "  Attempting uninstall: google-cloud-aiplatform\n",
      "    Found existing installation: google-cloud-aiplatform 1.43.0\n",
      "    Uninstalling google-cloud-aiplatform-1.43.0:\n",
      "      Successfully uninstalled google-cloud-aiplatform-1.43.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "cloud-tpu-client 0.10 requires google-api-python-client==1.8.0, but you have google-api-python-client 1.12.11 which is incompatible.\n",
      "ydata-profiling 4.6.5 requires pydantic>=2, but you have pydantic 1.10.14 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed absl-py-1.4.0 apache_beam-2.53.0 cloudpickle-2.2.1 crcmod-1.7 dill-0.3.1.1 dnspython-2.6.1 docopt-0.6.2 fastavro-1.9.4 fasteners-0.19 fire-0.6.0 google-api-core-2.17.1 google-api-python-client-1.12.11 google-apitools-0.5.31 google-auth-httplib2-0.1.1 google-cloud-aiplatform-1.36.1 google-cloud-bigquery-3.13.0 google-cloud-bigquery-storage-2.22.0 google-cloud-bigtable-2.23.0 google-cloud-datastore-2.19.0 google-cloud-dlp-3.16.0 google-cloud-pipeline-components-0.1.4 google-cloud-pubsub-2.18.4 google-cloud-pubsublite-1.9.0 google-cloud-recommendations-ai-0.10.10 google-cloud-spanner-3.44.0 google-cloud-videointelligence-2.13.3 google-cloud-vision-3.7.2 grpc-interceptor-0.15.4 hdfs-2.7.3 js2py-0.74 jsonpickle-3.0.3 kfp-1.8.22 kfp-pipeline-spec-0.1.16 kfp-server-api-1.8.5 kubernetes-25.3.0 numpy-1.24.4 objsize-0.6.1 orjson-3.9.15 plotly-5.18.0 pyarrow-14.0.2 pyarrow-hotfix-0.6 pydantic-1.10.14 pydot-1.4.2 pyjsparser-2.7.1 pymongo-4.6.2 regex-2023.12.25 strip-hints-0.1.10 termcolor-2.4.0 tzlocal-5.2 xgboost-2.0.1\n"
     ]
    }
   ],
   "source": [
    "! pip install --upgrade -r 'requirements.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d07214a67580"
   },
   "source": [
    "After you install the additional packages, you need to restart the notebook kernel so it can find the packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "18c113700b6f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Automatically restart kernel after installs\n",
    "import os\n",
    "\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    import IPython\n",
    "\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f31ae3fed8ab"
   },
   "source": [
    "### Setup your environment\n",
    "\n",
    "Run the next cells to import libraries used in this notebook and configure some options."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7d61a362443d"
   },
   "source": [
    "Run the next cell to set your project ID and some of the other constants used in the lab.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cellView": "form",
    "id": "wxiE6dEWOFm3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "from typing import Union\n",
    "\n",
    "import pandas as pd\n",
    "from google.cloud import bigquery\n",
    "\n",
    "# Generate unique ID to help w/ unique naming of certain pieces\n",
    "ID = \"\".join(random.choices(string.ascii_lowercase + string.digits, k=5))\n",
    "\n",
    "GCP_PROJECTS = !gcloud config get-value project\n",
    "PROJECT_ID = GCP_PROJECTS[0]\n",
    "BUCKET_NAME = f\"{PROJECT_ID}-fraudfinder\"\n",
    "REGION = \"us-central1\"\n",
    "TRAINING_DS_SIZE = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bd738fc1e201"
   },
   "source": [
    "### Create a Google Cloud Storage bucket and save the config data.\n",
    "\n",
    "Next, we will create a Google Cloud Storage bucket and will save the config data in this bucket. After the cell operation finishes, you can navigate to [Google Cloud Storage](https://console.cloud.google.com/storage/) to see the GCS bucket. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "7d3556c598a6",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gs://isogde-fraudfinder/...\n",
      "Copying from <STDIN>...\n",
      "/ [1 files][    0.0 B/    0.0 B]                                                \n",
      "Operation completed over 1 objects.                                              \n"
     ]
    }
   ],
   "source": [
    "config = f\"\"\"\n",
    "BUCKET_NAME          = \\\"{BUCKET_NAME}\\\"\n",
    "PROJECT              = \\\"{PROJECT_ID}\\\"\n",
    "REGION               = \\\"{REGION}\\\"\n",
    "ID                   = \\\"{ID}\\\"\n",
    "FEATURESTORE_ID      = \\\"fraudfinder_{ID}\\\"\n",
    "MODEL_NAME           = \\\"ff_model\\\"\n",
    "ENDPOINT_NAME        = \\\"ff_model_endpoint\\\"\n",
    "TRAINING_DS_SIZE     = \\\"{TRAINING_DS_SIZE}\\\"\n",
    "\"\"\"\n",
    "\n",
    "!gsutil mb -l {REGION} gs://{BUCKET_NAME}\n",
    "\n",
    "!echo '{config}' | gsutil cp - gs://{BUCKET_NAME}/config/notebook_env.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dc2dff7ba2e0"
   },
   "source": [
    "### Copy the historical transaction data into BigQuery tables\n",
    "\n",
    "Now we will copy the historical transaction data and ingest it into BigQuery tables. For this, we will need to run `copy_bigquery_data.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "4ac6e0bc33b1",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File copied from gs://cymbal-fraudfinder/datagen/hacked_customers_history.txt \n",
      "\t\t to gs://isogde-fraudfinder/datagen/hacked_customers_history.txt\n",
      "File copied from gs://cymbal-fraudfinder/datagen/hacked_terminals_history.txt \n",
      "\t\t to gs://isogde-fraudfinder/datagen/hacked_terminals_history.txt\n",
      "File copied from gs://cymbal-fraudfinder/datagen/demographics/customer_profiles.csv \n",
      "\t\t to gs://isogde-fraudfinder/datagen/demographics/customer_profiles.csv\n",
      "File copied from gs://cymbal-fraudfinder/datagen/demographics/terminal_profiles.csv \n",
      "\t\t to gs://isogde-fraudfinder/datagen/demographics/terminal_profiles.csv\n",
      "File copied from gs://cymbal-fraudfinder/datagen/demographics/customer_with_terminal_profiles.csv \n",
      "\t\t to gs://isogde-fraudfinder/datagen/demographics/customer_with_terminal_profiles.csv\n",
      "BigQuery table created: `isogde`.tx.tx\n",
      "BigQuery table created: `isogde`.tx.txlabels\n",
      "BigQuery table created: `isogde`.demographics.customers\n",
      "BigQuery table created: `isogde`.demographics.terminals\n",
      "BigQuery table created: `isogde`.demographics.customersterminals\n"
     ]
    }
   ],
   "source": [
    "!python3 scripts/copy_bigquery_data.py $BUCKET_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "29dbf432339c"
   },
   "source": [
    "### Check data in BigQuery\n",
    "\n",
    "After ingesting our data into BigQuery, it's time to run some queries against the tables to inspect the data. You can also go to the [BigQuery console](https://console.cloud.google.com/bigquery) to see the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e12ec3dae852"
   },
   "source": [
    "#### Initialize BigQuery SDK for Python "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ace8667cc99e"
   },
   "source": [
    "Use a helper function for sending queries to BigQuery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "f7afa36c6090",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Wrapper to use BigQuery client to run query/job, return job ID or result as DF\n",
    "def run_bq_query(sql: str) -> Union[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Run a BigQuery query and return the job ID or result as a DataFrame\n",
    "    Args:\n",
    "        sql: SQL query, as a string, to execute in BigQuery\n",
    "    Returns:\n",
    "        df: DataFrame of results from query,  or error, if any\n",
    "    \"\"\"\n",
    "\n",
    "    bq_client = bigquery.Client()\n",
    "\n",
    "    # Try dry run before executing query to catch any errors\n",
    "    job_config = bigquery.QueryJobConfig(dry_run=True, use_query_cache=False)\n",
    "    bq_client.query(sql, job_config=job_config)\n",
    "\n",
    "    # If dry run succeeds without errors, proceed to run query\n",
    "    job_config = bigquery.QueryJobConfig()\n",
    "    client_result = bq_client.query(sql, job_config=job_config)\n",
    "\n",
    "    job_id = client_result.job_id\n",
    "\n",
    "    # Wait for query/job to finish running. then get & return data frame\n",
    "    df = client_result.result().to_arrow().to_pandas()\n",
    "    print(f\"Finished job_id: {job_id}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "20875916c5d4"
   },
   "source": [
    "#### tx.tx\n",
    "The `tx.tx` table contains the basic information about each transaction:\n",
    "- `TX_ID` is a unique ID per transaction\n",
    "- `TX_TS` is the timestamp of the transaction, in UTC\n",
    "- `CUSTOMER_ID` is a unique 16-digit string ID per customer\n",
    "- `TERMINAL_ID` is a unique 16-digit string ID per point-of-sale terminal\n",
    "- `TX_AMOUNT` is the amount of money spent by the customer at a terminal, in dollars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "cc0e50b158d2",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished job_id: c49d26b5-1541-4ed6-8092-98632a67d8e5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TX_ID</th>\n",
       "      <th>TX_TS</th>\n",
       "      <th>CUSTOMER_ID</th>\n",
       "      <th>TERMINAL_ID</th>\n",
       "      <th>TX_AMOUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3e4ef9ddc16cd5a520f93fab795210fa3e855007</td>\n",
       "      <td>2025-10-16 18:29:27+00:00</td>\n",
       "      <td>6306004586824062</td>\n",
       "      <td>00064542</td>\n",
       "      <td>37.160000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5d6895421d0e828a34a8309ab4a16f8f8a92f344</td>\n",
       "      <td>2025-10-16 06:17:35+00:00</td>\n",
       "      <td>0291762451225654</td>\n",
       "      <td>00064542</td>\n",
       "      <td>5.130000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89efd1fa98a5c8f4c22feb698500acb17183a187</td>\n",
       "      <td>2025-10-16 12:17:47+00:00</td>\n",
       "      <td>3067754972043832</td>\n",
       "      <td>00064542</td>\n",
       "      <td>84.390000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59df60827bd9ea0b0a627e5de499a5e1d3e69383</td>\n",
       "      <td>2025-10-16 18:24:46+00:00</td>\n",
       "      <td>9038541296430573</td>\n",
       "      <td>00064542</td>\n",
       "      <td>88.720000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45c2abe62242553628c819515a5b4c93d5fcea0e</td>\n",
       "      <td>2025-10-16 03:31:33+00:00</td>\n",
       "      <td>3884437987790018</td>\n",
       "      <td>00064542</td>\n",
       "      <td>88.390000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      TX_ID                     TX_TS  \\\n",
       "0  3e4ef9ddc16cd5a520f93fab795210fa3e855007 2025-10-16 18:29:27+00:00   \n",
       "1  5d6895421d0e828a34a8309ab4a16f8f8a92f344 2025-10-16 06:17:35+00:00   \n",
       "2  89efd1fa98a5c8f4c22feb698500acb17183a187 2025-10-16 12:17:47+00:00   \n",
       "3  59df60827bd9ea0b0a627e5de499a5e1d3e69383 2025-10-16 18:24:46+00:00   \n",
       "4  45c2abe62242553628c819515a5b4c93d5fcea0e 2025-10-16 03:31:33+00:00   \n",
       "\n",
       "        CUSTOMER_ID TERMINAL_ID     TX_AMOUNT  \n",
       "0  6306004586824062    00064542  37.160000000  \n",
       "1  0291762451225654    00064542   5.130000000  \n",
       "2  3067754972043832    00064542  84.390000000  \n",
       "3  9038541296430573    00064542  88.720000000  \n",
       "4  3884437987790018    00064542  88.390000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_bq_query(\n",
    "    \"\"\"\n",
    "SELECT\n",
    "  *\n",
    "FROM\n",
    "  tx.tx\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5e0ab0d56773"
   },
   "source": [
    "#### tx.txlabels\n",
    "The `tx.txlabels` table contains information on whether each transation was fraud or not:\n",
    "- `TX_ID` is a unique ID per transaction\n",
    "- `TX_FRAUD` is 1 if the transaction was fraud, and 0 if the transaction was not fraudulent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "c128a6c78e82",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished job_id: 6ed67245-d46c-4765-8bea-ea45bbbe94aa\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TX_ID</th>\n",
       "      <th>TX_FRAUD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37e10ce51162dbeb371403e91f7b976bfaec33a6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>536f3365445f64f792d8de55c2efcad6c7298f0e</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0d30e250b96cc631f30cd6163402cae864fdb046</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>380c8b21240a5313cae01dc513ba603c5396f975</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>91ca1c138117ee9d1fc0020eacd0f1e9a9092fbb</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      TX_ID  TX_FRAUD\n",
       "0  37e10ce51162dbeb371403e91f7b976bfaec33a6         0\n",
       "1  536f3365445f64f792d8de55c2efcad6c7298f0e         0\n",
       "2  0d30e250b96cc631f30cd6163402cae864fdb046         0\n",
       "3  380c8b21240a5313cae01dc513ba603c5396f975         0\n",
       "4  91ca1c138117ee9d1fc0020eacd0f1e9a9092fbb         0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_bq_query(\n",
    "    \"\"\"\n",
    "SELECT\n",
    "  *\n",
    "FROM\n",
    "  tx.txlabels\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ffdfcfed70bd"
   },
   "source": [
    "### Check live streaming transactions via public Pub/Sub topics\n",
    "\n",
    "As part of the [README](README.md), you've created [subscriptions](https://console.cloud.google.com/cloudpubsub/subscription/) to public Pub/Sub topics, where there is a constant flow of new transactions. This means you have, in your own Google Cloud project, subscriptions to the public Pub/Sub topics. You will receive a Pub/Sub message in your subscription every time a new transaction is streamed into the Pub/Sub topic.\n",
    "\n",
    "There are two public Pub/Sub topics where there is a constant stream of live transactions occurring.\n",
    "\n",
    "The following Pub/Sub topics are used for transactions:\n",
    "```\n",
    "projects/cymbal-fraudfinder/topics/ff-tx\n",
    "projects/cymbal-fraudfinder/topics/ff-txlabels\n",
    "```\n",
    "\n",
    "Note: If you haven't completed the steps in the README, please make sure that you complete them first before continuing this notebook, otherwise you may not have Pub/Sub subscriptions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6bd15fba9b30"
   },
   "source": [
    "### Reading messages from the Pub/Sub topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "544309c7c12f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_from_sub(project_id, subscription_name, messages=10):\n",
    "    \"\"\"\n",
    "    Read messages from a Pub/Sub subscription\n",
    "    Args:\n",
    "        project_id: project ID\n",
    "        subscription_name: the name of a Pub/Sub subscription in your project\n",
    "        messages: number of messages to read\n",
    "    Returns:\n",
    "        msg_data: list of messages in your Pub/Sub subscription as a Python dictionary\n",
    "    \"\"\"\n",
    "    \n",
    "    import ast\n",
    "\n",
    "    from google.api_core import retry\n",
    "    from google.cloud import pubsub_v1\n",
    "\n",
    "    subscriber = pubsub_v1.SubscriberClient()\n",
    "    subscription_path = subscriber.subscription_path(project_id, subscription_name)\n",
    "\n",
    "    # Wrap the subscriber in a 'with' block to automatically call close() to\n",
    "    # close the underlying gRPC channel when done.\n",
    "    with subscriber:\n",
    "        # The subscriber pulls a specific number of messages. The actual\n",
    "        # number of messages pulled may be smaller than max_messages.\n",
    "        response = subscriber.pull(\n",
    "            subscription=subscription_path,\n",
    "            max_messages=messages,\n",
    "            retry=retry.Retry(deadline=300),\n",
    "        )\n",
    "\n",
    "        if len(response.received_messages) == 0:\n",
    "            print(\"no messages\")\n",
    "            return\n",
    "\n",
    "        ack_ids = []\n",
    "        msg_data = []\n",
    "        for received_message in response.received_messages:\n",
    "            msg = ast.literal_eval(received_message.message.data.decode(\"utf-8\"))\n",
    "            msg_data.append(msg)\n",
    "            ack_ids.append(received_message.ack_id)\n",
    "\n",
    "        # Acknowledges the received messages so they will not be sent again.\n",
    "        subscriber.acknowledge(subscription=subscription_path, ack_ids=ack_ids)\n",
    "\n",
    "        print(\n",
    "            f\"Received and acknowledged {len(response.received_messages)} messages from {subscription_path}.\"\n",
    "        )\n",
    "\n",
    "        return msg_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "583454c80a46"
   },
   "source": [
    "#### Reading from the `ff-tx-sub` subscription\n",
    "\n",
    "Now let's read from the `ff-tx-sub` subscription. You should see some recent transactions (in UTC timezone)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "40e3b8abc1cc",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received and acknowledged 2 messages from projects/isogde/subscriptions/ff-tx-sub.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'TX_ID': '1eaedf454ba6a70a00b46ca0dea7101509c8ce53',\n",
       "  'TX_TS': '2024-03-20 02:29:49',\n",
       "  'CUSTOMER_ID': '0890080443812200',\n",
       "  'TERMINAL_ID': '86017961',\n",
       "  'TX_AMOUNT': 10.56},\n",
       " {'TX_ID': '58d6d17e6b4e6484396099d5ec50b72c17a84ac7',\n",
       "  'TX_TS': '2024-03-20 02:29:57',\n",
       "  'CUSTOMER_ID': '3883628224884795',\n",
       "  'TERMINAL_ID': '66452946',\n",
       "  'TX_AMOUNT': 47.62}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages_tx = read_from_sub(\n",
    "    project_id=PROJECT_ID, subscription_name=\"ff-tx-sub\", messages=2\n",
    ")\n",
    "\n",
    "messages_tx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7b5f23c94328"
   },
   "source": [
    "#### Reading from the `ff-txlabels-sub` subscription\n",
    "\n",
    "We will do the same with `ff-txlabels-sub` subscription, which receives the same stream of transactions as `ff-tx-sub`, but also contain the ground-truth label, `TX_FRAUD`, if the transaction is fraudulent (1) or not (0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ccd79c9037b9",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received and acknowledged 2 messages from projects/isogde/subscriptions/ff-txlabels-sub.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'TX_ID': 'd88cc5319d15877b8e82717b936835bc5e473709', 'TX_FRAUD': 0},\n",
       " {'TX_ID': '279f251f883e0538b68735204d7488eead6660e2', 'TX_FRAUD': 0}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages_txlabels = read_from_sub(\n",
    "    project_id=PROJECT_ID, subscription_name=\"ff-txlabels-sub\", messages=2\n",
    ")\n",
    "\n",
    "messages_txlabels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "de7be6182813"
   },
   "source": [
    "### END\n",
    "\n",
    "Now you can go to the next notebook `01_exploratory_data_analysis.ipynb`"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "00_environment_setup.ipynb",
   "toc_visible": true
  },
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m118",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m118"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
